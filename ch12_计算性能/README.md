# 计算性能

在深度学习中，数据集和模型通常都很大，导致计算量也会很大。
因此，计算的性能非常重要。
本章将集中讨论影响计算性能的主要因素：命令式编程、符号编程、
异步计算、自动并行和多GPU计算。
通过学习本章，对于前几章中实现的那些模型，可以进一步提高它们的计算性能。
例如，我们可以在不影响准确性的前提下，大大减少训练时间。

## 12.1 编译器和解释器

- `torch.jit.script`
- `__enter__`与`__exit__`

## 12.5 多GPU训练

> 这里介绍的是`数据并行`

对于n个GPU：
1. 将一个小批量分成n块
2. 每个GPU都拿到模型的完整参数计算其中一块数据的梯度
3. 将所有GPU计算的梯度相加，然后将梯度和再传给各GPU(例如，将所有其他GPU的梯度都传到第0块GPU上，由GPU0进行求和，然后分发给其他GPU)
4. 每个GPU根据梯度更新参数

## 12.6 多GPU的简洁实现

- `nn.DataParallel`

